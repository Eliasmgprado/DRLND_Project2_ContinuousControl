{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Reacher.app\"`\n",
    "- **Windows** (x86): `\"path/to/Reacher_Windows_x86/Reacher.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Reacher_Windows_x86_64/Reacher.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Reacher_Linux/Reacher.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Reacher_Linux/Reacher.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Reacher.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Reacher.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='Reacher_Windows_x86_64_v2/Reacher.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, a double-jointed arm can move to target locations. A reward of `+0.1` is provided for each step that the agent's hand is in the goal location. Thus, the goal of your agent is to maintain its position at the target location for as many time steps as possible.\n",
    "\n",
    "The observation space consists of `33` variables corresponding to position, rotation, velocity, and angular velocities of the arm.  Each action is a vector with four numbers, corresponding to torque applicable to two joints.  Every entry in the action vector must be a number between `-1` and `1`.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "# states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "# scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "# while True:\n",
    "#     actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "#     actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "#     env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "#     next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "#     rewards = env_info.rewards                         # get reward (for each agent)\n",
    "#     dones = env_info.local_done                        # see if episode finished\n",
    "#     scores += env_info.rewards                         # update the score (for each agent)\n",
    "#     states = next_states                               # roll over states to next time step\n",
    "#     if np.any(dones):                                  # exit loop if episode finished\n",
    "#         break\n",
    "# print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DDPG Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from utils import Config\n",
    "from nn import Actor, Critic, ContinuousActorCriticNet\n",
    "from agent import DDPG_Agent, PPO_Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "class PPO_Trainer():\n",
    "    ''' Train PPO agent. '''\n",
    "    \n",
    "    TARGET_SCORE = 30                             # Enviroment average target score over 100 consecutive episodes\n",
    "    def __init__(self, agent, n_agents=1):\n",
    "        '''\n",
    "        Params\n",
    "        ======\n",
    "        agent (object): PPO agent class\n",
    "        n_agents (int): Number of parallel agents\n",
    "        '''\n",
    "        self.agent = agent\n",
    "        self.n_agents = n_agents\n",
    "        self.scores_deque = deque(maxlen=100)     # last 100 scores\n",
    "        self.scores_ep = []                       # list containing scores from each episode\n",
    "        self.max_score = 0                        # initialize agent max score \n",
    "\n",
    "    def train(self, n_episodes=1000, print_every=100, verbose=True, save=True, \n",
    "              save_name='', stop=False):\n",
    "        ''' Train the agent. '''\n",
    "        \n",
    "        start_time = time.time()                   # register start time\n",
    "        num_agents = self.n_agents\n",
    "        \n",
    "        for i_episode in range(1, n_episodes+1):\n",
    "            \n",
    "            self.agent.reset()\n",
    "            \n",
    "            scores = self.agent.step()\n",
    "            scores = np.sum(scores, axis=0)\n",
    "\n",
    "  \n",
    "            self.scores_deque.append(np.mean(scores))\n",
    "            self.scores_ep.append(np.mean(scores))\n",
    "\n",
    "            exec_time = time.time() - start_time\n",
    "            print(f'\\rEpisode {i_episode}\\tAverage Score: {np.mean(self.scores_deque):.2f} ' + \\\n",
    "                  f'exec.time: {str(datetime.timedelta(seconds=exec_time))}', end=\"\")\n",
    "\n",
    "            if i_episode % print_every == 0 and verbose:\n",
    "                print(f'\\rEpisode {i_episode}\\tAverage Score: {np.mean(self.scores_deque):.2f} ' + \\\n",
    "                      f'exec.time: {str(datetime.timedelta(seconds=exec_time))}')\n",
    "\n",
    "            ## Check if eviroment is solved and save checkpoint\n",
    "            if np.mean(self.scores_deque) >= self.TARGET_SCORE and len(self.scores_deque) == 100:\n",
    "                if self.max_score == 0:\n",
    "                    print(' <-- Objective Achived!')\n",
    "                    print(f'- Average score of +{np.mean(self.scores_deque):.2f} over 100 consecutive episodes')\n",
    "\n",
    "                    if stop:\n",
    "                        print('- Trainining Finished -')\n",
    "                        print(f'- Total training time:\\t{str(datetime.timedelta(seconds=exec_time))}')\n",
    "                        \n",
    "                    \n",
    "                        if save:\n",
    "                            torch.save(self.agent.network.state_dict(), f'checkpoint_ppo_net_{save_name}.pth')\n",
    "                            \n",
    "                            with open(f'scores_{save_name}.pkl', 'wb') as handle:\n",
    "                                pickle.dump(self.scores_ep, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                            \n",
    "                        return self.scores_ep, i_episode\n",
    "\n",
    "                if np.mean(self.scores_deque) >= self.max_score:\n",
    "                    max_score = np.mean(self.scores_deque)\n",
    "\n",
    "                    if save:\n",
    "                        torch.save(self.agent.network.state_dict(), f'checkpoint_ppo_net_{save_name}.pth')\n",
    "\n",
    "        exec_time = time.time() - start_time                   # compute training time\n",
    "\n",
    "        ## save training scores\n",
    "        if save:\n",
    "            with open(f'scores_{save_name}.pkl', 'wb') as handle:\n",
    "                pickle.dump(self.scores_ep, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "        print('- Trainining Finished -')\n",
    "        print(f'\\t-Total training time:\\t{str(datetime.timedelta(seconds=exec_time))}')\n",
    "        if self.max_score > 0:\n",
    "            print(f'\\t-Maximum average score of +{max_score} over 100 consecutive episodes')\n",
    "        else:\n",
    "            if stop:\n",
    "                return self.scores_ep, 9999\n",
    "            print('!!! Objective NOT achived !!!')\n",
    "        return self.scores_ep\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "\n",
    "config.batch_size = 128\n",
    "\n",
    "\n",
    "config.gamma = 0.99\n",
    "# config.tau = 1e-3\n",
    "config.gae_tau = 0.95\n",
    "config.lr = 5e-5\n",
    "config.l2_reg = 0\n",
    "config.clip_grad = 1\n",
    "\n",
    "config.fc1_act = 400\n",
    "config.fc2_act = 300\n",
    "config.fc1_crit = 400\n",
    "config.fc2_crit = 300\n",
    "config.trajectory_steps = 1000\n",
    "config.SGD_epoch = 10\n",
    "\n",
    "config.epsilon = 0.1\n",
    "config.beta = 0.01\n",
    "\n",
    "config.add_noise = True\n",
    "\n",
    "config.bn = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('PPO_config.pkl', 'wb') as handle:\n",
    "    pickle.dump(config, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.brain_name = brain_name\n",
    "config.env = env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = PPO_Agent(state_size, action_size, random_seed=420, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PPO_Trainer(agent, num_agents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 2.81 exec.time: 0:35:30.431455\n",
      "Episode 200\tAverage Score: 13.78 exec.time: 1:12:21.795442\n",
      "Episode 300\tAverage Score: 26.73 exec.time: 1:49:03.906161\n",
      "Episode 342\tAverage Score: 30.07 exec.time: 2:04:32.573378 <-- Objective Achived!\n",
      "- Average score of +30.07 over 100 consecutive episodes\n",
      "- Trainining Finished -\n",
      "- Total training time:\t2:04:32.573378\n"
     ]
    }
   ],
   "source": [
    "scores, _ = trainer.train(n_episodes=500, print_every=100, verbose=True, save=True, stop=True,\n",
    "                          save_name='PPO_test_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEGCAYAAABsLkJ6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA1gklEQVR4nO3dd3wc1dXw8d/Rqvde3CT3gjuywWDAmBLTAgTekAYkISENUt7kfR4IyRNISCEFUh8SE4oJYBICSehgsMEY4yIb9yrb6r2XVVnt3vePGa2KJVvYXu1Ke76fjz7anZndOQzynLl37pwrxhiUUkoFnxB/B6CUUso/NAEopVSQ0gSglFJBShOAUkoFKU0ASikVpEL9HcBQpKammpycHH+HoZRSI8q2bdtqjDFpg60fEQkgJyeHvLw8f4ehlFIjiogUnmi9dgEppVSQ8lkCEJFIEdkiIjtFZK+I3Gcvf0JEjonIDvtnvq9iUEopNThfdgF1AMuNMS0iEgZsEJHX7HX/zxjzTx/uWyml1En4LAEYq8ZEi/02zP7RuhNKKRUgfHoPQEQcIrIDqALWGGM226t+KiK7ROQhEYnwZQxKKaUG5tMEYIxxG2PmA+OAxSIyG7gbmAEsApKB/x7osyJyu4jkiUhedXW1L8NUSqmgNCyjgIwxDcA6YIUxptxYOoDHgcWDfGalMSbXGJObljboMFallFKnyJejgNJEJNF+HQVcBhwQkSx7mQDXAXt8FYNSSo1UVc3t/OqNAxytbjn5xqfIly2ALGCdiOwCtmLdA3gZeFpEdgO7gVTgfh/GoJRSI9Lhyhb+tO4IFU3tPtuHL0cB7QIWDLB8ua/2qZRSo0VJvROA8UnRPtuHPgmslFIBqLiuDUeIkJUQ6bN9aAJQSikfMMZwoKLplD9fXO8kKyGSUIfvTtOaAJRSygf+vrWYFb99j435Naf0+ZL6Np92/4AmAKWU8ol3DlrPLxXUOk/p88V1TsYlRZ3JkI6jCUAppXyguqUDYMijeFo7umhwdgLQ7nJT1dzB+GRtASil1Iji9hj2l1v9/4W1rcet31/exLGavstveHgj83+8BoD8Kmvsf05qjE/jHBETwiilVCDr6HLjchtiI6xT6oGKJpydbuD4LqDiOidX/O49AH52/RyOVrfw3cunc6Ci2bt+R3EDAPPHJfo0bk0ASil1mn76yn4+LGrgpTuXArAxvxaAS2ems62wvs+2z24t8r7+4X/24PYYPL3qJL9zqJqdxQ0kx4QzPlnvASilVMAwxmBVu++xu7SR/eVNuNweAN4/UsPktBgWT0ym3umi0ekCwOMxPJdXwqUz0xmbGIXbPvM/tbln5saXdpTxYVE9C8YnYlXM8R1NAEopNUQej2HpA+v426a+U+0W1Trp8hj2ljVx+UPv8s7Bas6fkkp2itWHX1hn9ffvKWukqrmDq+ZmMSmtp3+/s8tKHJPSYthSUMeR6laWTE7x+X+PJgClVFB7enMh33hmu/d9g7OTZb9a5+2H7622tZPShjb+kVeM22PYUdxAS0cXta3W6J3PPrKJghonV8/N4jPnTCDHTgDd9wHeOViNCFw4NY2J9g3eueMSvN//7UuncfXcLL62bDJfOH+ir/6TvfQegFIqaGwrrCc7JZrU2J55qNYdqOKdg9W4PQZHiPDuoWoKap384e3D/Pnms2lzualr6SQnNYZKe0jnntImHt1wlJ+9eoDPn5fj/a7WTjdfvWgyd10xA4A2+0ZwUW0rxhje3FfB3HGJpMRGMMlOAJfOzGBXSSMAmfGR/PEzC4fjUADaAlBKBQljDLc8uplH1h/ts7y4ro0uj6HGHrdfXGddre8ta2LOvW/wmUc2sezX79DY5vImAIA/rM0H4ImNBX2+b8XsTO/rqHAHGfERFNQ6eT+/lj2lTfyfs8cBMC0zDoDcnCTv9ulxwztBoiYApVRQcHa6ae20HrDqZoyh2K66WdrQBlg3dMF6gKvd5WFPqTWe/1/bS7wPdaXEhNPc3sX0jDhiwh199jN3bEKf99kpMRTWtvKX9UfIjI/k/+RaCWDJpBT+fvu5LJnU09efHj+8CUC7gJRSQaGhzRqJU+/sxOMxrDtYxYGKZu94/bKGNuaNS2S33R3T3/PbS7l4RjoicGPuOP7y7lE+NjuTaRmxrD1QxSUzMnAbQ0hI35E72cnRPLetBBG48+IpRIRaCUNEOMc++afFRVDd3EF0+PCekjUBKKWCQr19o7a+tZNNR2u5bVVen/XlDe18/vEtlDW2ExXmoM3l9q6LjQjlYEUz0zLiSI2N4BMLxvH4+wUsm57GwglJXD13zKD7PTs7iee2lWAMXLtg7IDbvPLNpZQ3+G7il8FoAlBKBYUGeyx+nbOTEru7p7f95U28d7iG25ZOJCshkvtf2e9dd828LFZvKWbT0Voy4yOZnhnH3vs+RtgQSjXftGg8NS0dlDe2MzktdsBt0uMiSY/zXd3/wWgCUEoFhXq70FpDq4tq+z6AI0RwewxZCZGs2V8JwLLpad5uobPGxHO4soVr5o1h9ZZiShvamJll3bwdyskfrK6eO5ZPPdP/OWeEJgClVFDovgfQ3NFFaUMbcRGhvPqtC/jgSC1v7K3g7QNVAJw1JgGHCNcvGMtdV8ygud3FuF51+adlxPklfl/QBKCUGrGe2VzEwYom7rt29km3bbDvAQAcrmwmLT6C8cnRjE+OJiYi1JsAkmPCAXjopvkAZMT37Zr50gWTzlD0/uezBCAikcB6IMLezz+NMT8SkYnAs0AKsA242RjTOfg3KaXU8d7aV8n3/7UbgK8tm0Jmv7lzO7s87C5tZOEEq6ZOvX0PAOBQZQszMnuu5LvH7i/OSR50f6u+uJjQEPEmiNHAl88BdADLjTHzgPnAChE5F3gAeMgYMwWoB27zYQxKqVFqW1FPlc0tBXXHrX/s/WPc8PBGHnrrMAANbT3XmY1tLtJ7Xdk7QoSd/3M5T3xx0aD7u2haGudPST0ToQcMnyUAY2mx34bZPwZYDvzTXr4KuM5XMSilRq/KpnYy4iOIjQhl81Gr/LLL7eG//rmTw5XN7LRr+fxh7WFWbynihe2lhPe6cZsW2/ehq4TosGEfh+9vPn0SWEQcIrIDqALWAEeABmNMl71JCTDwwFillDqByqZ2xiRGkZuTxFv7K2lud3G4soV/5JXwtae3s7u0kanpsRgDd79gdRV12uWawXr4Ktj5NAEYY9zGmPnAOGAxMGOonxWR20UkT0TyqqurfRWiUmqEqmzqIDM+km9eMpXq5g5+/cZBKpqs8f35VS2U1Ldxw9nj+pRdvmhaGtkp1oielNjR05d/qoalvWOMaRCRdcASIFFEQu1WwDigdJDPrARWAuTm5pqBtlFKBa/KxnaWTkll4YQkVszOZM2+Sian933Qau64BMYkRnGgvIlbz8shMsyBCPzl3SMsn5Hup8gDhy9HAaUBLvvkHwVchnUDeB1wI9ZIoFuB//gqBqXU6NTa0UVzR5d3iGZudjKv7q5ga0Hf6Rdzs5MJDw3h4/P6lmr4fx8bcmfEqObLFkAWsEpEHFhdTf8wxrwsIvuAZ0XkfuBD4FEfxqCUGkVaO7r41RsH+deHVsdBhl09c2G2VVL5pZ1lRIU5SIoO45c3ziM8VAsen4jPEoAxZhewYIDlR7HuByil1JAYY3j43SO8sL2U/KoW7/LuFsCsrHgiQkPo6PKweGIyq76op5ih0PSolApI/9hazIrfruepTYXc8tgWfvn6QUJDhD9/biFfvWgygPeGbnhoiLfOfpjDtxOpjybSf3b7QJSbm2vy8vJOvqFSalRwuT1Mvec1AETAGGsEz+OfX0RIiGCMoaq5o0+ZhnaXm+8+t5Obcsdz4bQ0f4UeUERkmzEmd7D1wfXUg1JqRFhr1+UB6+T/g6tm8sXzJ3onWxGR42r0RIY5+NMwzqc7GmgXkFIq4Bwob0YExiZGAXD+lNTjZtpSp08TgFLKr+pbO6lt6eizrLC2laz4SC6blUFWQiTTR1EJ5kCiXUBKKb9ocHZypLqVLz+ZR11rJwW/uMq7rrDOyYSUaO66YgZ3Lp+iV/8+oi0ApdRpWfrAWm5+dPNJt3N2drHk52+z7qDVv//Htfl8euUm6uw6/cV1Tn7x2gHyq1oorHWSkxJDZJiDlFit2eMr2gJQSp2Wkvo2SuqtGjzGGNbsq2TuuMQ+9fmf3lyIx0B5Yzs7ixu4eHo6O0sa+hRnu+HhjVQ1d1Da0EZNSwcTUqKP25c6szQBKKVOyZp9law9UNln2YfFDdz+t20AbP7+Jd6ROg++eQiH3Y1T2dSB22PYW9bU57NV9jy9RXVOALKTY1C+pQlAKXVKntpUyLuH+lbqrWpq976uaGwnIz6SLreHOmcn3Y8cbTxSw/QfvEaXp+cZpJU3n01MRCh3vbCLvaWNQM9DXsp3NAEopT4yYww7SxqOW9572sVdpY08uuEYMREOej9vWljr9L4Ocwgut2HBhCTS4iKYmh5HcZ3VnaQJwPc0ASilPrKiOicNvU72AG6P8d7QBfjzO0cobWgb9DvuvmIG7x+pJa+gjlS7Nn93cbfkmHDiIsN8ELnqTROAUuoj21nSeNyylvYu6nslgIpe3UH9zcqK5ysXTWZKeiznTU5BxLo/0H3PQK/+h4cOA1VKfWR7yxoJd4TwvcunkRxjXb03tbuod7qIDLNOK27P4HXGEqOtq/tLZmZ4C7sBZHYngGRNAMNBE4BS6iPLr2xhUloMdyyfys8/MQeAxjYX9c5Oxif1nLxDB3mAKzZi4M6HDHvo6IQUHQE0HDQBKKUGtOFwDR//4wZ+9ur+49blV7d4p1+Mt/vqV20sYE9pI5kJkd6SzLPGxPf5XHc+WDAhacB9jk+yav9MTtMEMBw0ASgVJApqWplz7xvsKT2+/763LreHAxVNPLOlkF0ljbyyq9y7buORGlo6uiiqczK1OwFEWVfzz20roaq5g6TocGLsK/wpabGEhoj3xH/V3DE88+Vz+MqFkwbc95T0OJ667RyumpN1uv+5agj0JrBSQWLLsTqa27t4fU8Fs8cmDLrdT1/dz+PvF5AeZ43IaXBaN3bzq1r4zCOb+fIFEzEGpvRrAXRLjgknNiKUBqeLhOgwshIjCQsJ4WhNKykx4Zw3OfWEcS6deuL16szRFoBSQWJfufXk7Yb8Gu+ylo4uWju6+mz3sn3F3/1kbmunm+Z2FwU1rQC8ursC6JUAovomAEeIePv44yPDWDIphfOnpHLVnCyWTtGTeyDRFoBSQWKfXXphV0kDT28u5D8flrGjpIH4yDDyfnCpd7vGXuP7J6XFcLS6lcqmDkrqrQe4ShvaCA8NYXKalQDi+t3QrW/t7EkAUWF857JpPv3vUqdOWwBKjXJ3v7CLpzcXsq+8ibGJUXgM3POvPWwpqKOzy0NNSwfGGH7/9mH2lDb2KdC2YLx1s7aqqd1b8A1gZlY8YQ7r9NG7VPOtS7L5zmXTvPcA4iP1GjOQ+ez/joiMB54EMgADrDTG/E5E7gW+DHQXEfm+MeZVX8WhVLBbvaUYKAbg+gVj+dumwuO2Kapz8uCaQzy45lCf5QsmJPL89hI25Nd4u5AA5oztO7rnh1fPYmZWnLd/PzaypwWgApcv03MX8F1jzHYRiQO2icgae91Dxphf+3DfSqkBLJ2aOmAC2F/e7H0dHxnKvPGJvHe4hgUTEgH433eO9Nl+Tr+byLctndjnfWx4zz0AFbh8lgCMMeVAuf26WUT2A2N9tT+l1PH6P427YEIiEaEhdHR5+izvPTT0qrlZxEaE8n5+jbefv9usrHjCQkO4cFraCffb0wLQLqBANiz3AEQkB1gAdE8bdIeI7BKRx0RkwCdCROR2EckTkbzq6uqBNlFKnYSzs2eET1xEKGmxEWTZT9vesiSbp247B4A9ZT0J4HPnZnPb0kmsvDmXyDBHn++7bFYG//nG+WQlRJ1wv71HAanA5fP0LCKxwPPAt40xTSLyMPATrPsCPwF+A3yx/+eMMSuBlQC5ubmDFxVRSg2qrdPtfT0pLQYRISM+koJaJ3PHJXL+lBQiw0K8LYC1372ISfZVf/eMXh/cvZzIUAdOl5u0IU7PmBEfSXhoCEl2nSAVmHyaAEQkDOvk/7Qx5gUAY0xlr/WPAC/7MgalgpmzTwKwTuzdLYDM+EhEhLGJURyptsb4D3TTtvtqf+DiDQO74eyxLJmcMmjNHxUYfNYFJFZ910eB/caYB3st7/2M9/XAHl/FoFSw650AFto3dDPtE3pmgnU1nx7XM3dv3BkathkR6mBiqtbzCXS+TM/nAzcDu0Vkh73s+8CnRWQ+VhdQAfAVH8agVFBrc1n3AB65JZdLZqQD1giepOgwxiZaVTvT7UlYIsNCiAh1DPxFalTy5SigDcBAtWB1zL9SZ8CafZW0udx8fN6YQbfpbgEkRod5H9i6ck4mV8zO9L7vrvmjM3AFH+2gU2qE+vKTeQDHJYBGp4t95U0smZziTQBRvUbziAjS69Ksuwto4Mr9ajTTUhBKjUBdbs+g63704h4+/cgmjtW0ekcBRYUP3rXT3QXU/9kANfppC0CpEaig1ul9bYzxzqkLeGv2XPzrd4ixT/zRJ0gAaXHdCcA96DZqdNIWgFIBbtLdr/DA6wf6LDtQ0VOXp93V98q9zdVzIm+1WwDRYYNf63V3AfX/HjX6aQJQKoC53B48Bh7uV4vnYEVP7Z56e8IWsFoDx2paWTIppU8lzhN1AXW3AFTw0QSgVABrae8acPlR+8Et6JsAKpracXa6uXJOJv+3Vx3+8NDB/6l3J4rPnTvhdMNVI4zeA1AqgDX3SgC9+/pL6p2Eh4bQ2eXhWE0rU9JjiQh1eBPDpLRYmtpcA35nfyLC4Z9egUN0HFCw0RaAUgGsqb3nJF7T0nOlX1Lf5i3JfMczH/LFJ7by8q4ydts1fSanxZIeH8lQhTlC+kzsooKDtgCUClCFta19yjQX1LaSFheBs7OL2tZOrpk3hm2F9QC8n1/L+/m1ACREhZERH4HrBENFlQJNAEoFrLue380HR2u9749WtzAjM45VGwsAmN1vUpZu0zPjEBHv+H6lBqMJQKkAVdLg7PP+1d0VlDe289u3DgNWeeduty2dyFv7KymsdTIjMw5A6/qok9J7AEoFIGMMlU0d3ve3LMlm/eFqCns9ADYuqWdSlh9ePYvPLLZG8UzLiBu+QNWIpi0ApQJQg9NFZ6/SDDctGs+THxTyzsEqwCrtnBoTwU2540mNsyZduWh6Gr996zDnTEz2fu7vt5973KxeSnXTBKBUAKpsbu/zfnyyVbq53ukiOyWaF75+PgAP3DjXu82MzHj2/2RFn8+dMynFx5GqkUy7gJQKQL27f8Caz7f7Ya7EaJ1mUZ0ZmgCUCkCVTX1bACLinY83OVrr9qszQxOAUgGoql8CgJ6aPTrRujpTNAEoFUAanS5e2VVOZVMHif2u9FO9LQBNAOrM0JvASgWQLz25la0F9SzKSSI1NoIGp4swh1WiQVsA6kzTBKBUANlaYJV2OFbTysTUGN78zoXE23P1ehOAtgDUGeKzLiARGS8i60Rkn4jsFZFv2cuTRWSNiBy2fyf5KgalAtWe0kY25tf0WdZ7msealk4SosKZlhFHZoJV1C0t1jrxJ8foTWB1ZvjyHkAX8F1jzCzgXOAbIjILuAt42xgzFXjbfq9UULn6Dxv4zF8391m2v7y5z/ukfvcA0uyZu7QFoM4UnyUAY0y5MWa7/boZ2A+MBa4FVtmbrQKu81UMSgU6Y4z39f5e0zwCx90EXjY9je9fOYOzs7XRrM6MYRkFJCI5wAJgM5BhjCm3V1UAGYN85nYRyRORvOrq6uEIU6lh0bvGf3NHz4QvRbV9i7/1f+ArMszB7RdOJtShg/fUmeHzvyQRiQWeB75tjOlziWOsyx8z0OeMMSuNMbnGmNy0tDRfh6nUsMmvavG+rur1xG9hnZMJydHeUT/9WwBKnWk+TQAiEoZ18n/aGPOCvbhSRLLs9VlAlS9jUMrfKpva+0zO0icB9Kr5U1TbSnZKtPfKPzFK+/qVb/lyFJAAjwL7jTEP9lr1InCr/fpW4D++ikEpf2tsc7HsV+94J3EB2FfW0xD++tPbeX5bCWC1AMYnR5MYZV35978JrNSZNuQEICJRIjL9I3z3+cDNwHIR2WH/XAn8ArhMRA4Dl9rvlRqVNh+tpc3lZtPROgA6uzy8tLOMJXaVzgani9+vPUyj00WD00V2crR3lE+CJgDlY0N6EExErgF+DYQDE0VkPvBjY8zHB/uMMWYDMNgs05d8xDiVGpE2HrGmdNxZ0oAxhtVbiqht7eT2Cyd5p3ssrHVyx+rtAExMjfGe+HW4p/K1obYA7gUWAw0AxpgdwESfRKTUKLIhvwYRqG7uYOX6o/zoxb0smZTChdN6BjZEhzt473ANK87KZNn0dG/Xj94EVr421FIQLmNMo9Wt7zXg6B2llGVvWSP5VS1cN38M/95Rxs9fO0BudhKrvrgYR4hw87nZuI3hzuVTaO1wMzktBhFhTGIUidFhROlMXsrHhpoA9orIZwCHiEwFvgls9F1YSo0cFY3tpMdFEBIiODu7OFbTyqyseJ7aVES4I4QfXj2L7JQY9pY18qNrzvJO7PKT62YP+H23XziJGxaOo98Fl1Jn3FATwJ3APUAH8AzwBnC/r4JSaqRocHZy0a/W8Y2Lp/DNS6Zyy6NbyCus54vnT2T1liI+mTuOlNgIvnPZtCF/Z3R4KNHJWqdR+d5J/8pExAG8Yoy5GCsJKKVsu0sb6ejy8Mh7R/nUovHkFVrVPP+2qYDzJqfws+vn+DlCpQZ30pvAxhg34BGRhGGIR6kRod3lpt3lZldJIwDN7V3c+vhW73qX25Cbk6xlG1RAG2o7swXYLSJrgNbuhcaYb/okKqUCWLvLzdx73yQ3J4mEqDCyU6KZnBbL2gNVnJ2dxM7iBro8hpmZcf4OVakTGmoCeMH+USroPfzOETrdHjYeqWVcUhTzxify9WWTqW7u4GfXz+HO1ds5VNnCjKx4f4eq1AkNKQEYY1aJSDjQfSfroDHGdaLPKDVabbAncnGECCX1bXxq0XjOGpPAS3cuBWBqRhzFdW1MSI72Z5hKndRQnwRehlW7vwDr6d7xInKrMWa9zyJTKsAU1zn557YS9pU1Ee4IodMu8JaTGtNnu29dMpXr5o/FEaLDOFVgG2oX0G+Ay40xBwFEZBqwGjjbV4EpFSiMMWw8Usvj7xfw1v5KAK6YnclreyoAyEnpmwCmZcQxLUP7/1XgG+oQhbDukz+AMeYQoM+pq6Cw+Vgdn/3rZu/JH+DSmT3zGPVvASg1Ugy1BZAnIn8FnrLffxbI801ISgWO4jon7x46fka6ZdOtWj7pcRHERuhDW2pkGupf7teAb2CVgAB4D/hfn0SkVIBwewwX/HJdn2XfuXQaS6emkhIbQUJUmF79qxFtqAkgFPhd98Qu9tPBET6LSik/aOnoYn95E4tykgGoaemZrjEm3EFrp5tl09OYNz4RgGvmZTElLdYfoSp1Rgw1AbyNNXlL91x2UcCbwHm+CEopf3h6UyEPvH6AbT+4jKSYcCoareka0+IiePpL59DU5vKe/AHuv07LPKiRbagJINIY453I1BjTIiI6yFmNKgW1TjwGCmpbrQTQZCWAx25dpKN61Kg01FFArSKysPuNiOQCbb4JSanhs2pjAQU1VnWTknonAEV11u9KOwFkJGhvpxqdhtoC+DbwnIiU2e+zgJt8EpFSw6SquZ0fvbiXlJhwtv3wMkobrGuawlorAVQ0thMaIqTGaAJQo9MJWwAiskhEMo0xW4EZwN8BF/A6cGwY4lPKZw5WNANQ29pJZ5eHsv4JoKlnohelRqOTdQH9Bei0Xy8Bvg/8CagHVp7ogyLymIhUicieXsvuFZFSEdlh/1x5GrErdVq6EwDASzvLaHdZpR2K6qwuocqmdjISIv0Sm1LD4WQJwGGMqbNf3wSsNMY8b4z5ITDlJJ99AlgxwPKHjDHz7Z9XP1q4Sp05ByqaiY8MJSk6jF+/aT3onhQd5m0BlDW0kxmvCUCNXidNACLSfZ/gEmBtr3UnvH9gF4qrO9E2SvnTwYpm5o5L5FOLJ1BuD/lcPiODquYOXt5VxrGaVs6ZmOznKJXynZMlgNXAuyLyH6xRP+8BiMgUoPEU93mHiOyyu4iSBttIRG4XkTwRyauuPv5RfKWGorndxSf/8gFHqlv6LHd7DIcqm5meGccXzsvhkhnp/OS62dywcCwAdzzzIVkJkXxq8QR/hK3UsDhhAjDG/BT4LlZ3zlJjjOn1uTtPYX8PA5OB+UA5VpXRwfa90hiTa4zJTUtLO4VdKQVrD1Sx5VgdD755qM/ywtpWOro8TM+MIz0+kkc/v4ibz83mrLE9M5/etGg8kWGO4Q5ZqWFz0mGgxphNAyw7NNC2Q/gubzlFEXkEePlUvkepoWp3uQGICLOudfaVNXGkuoUwhzWyZ0a/aRsTonqK3F4xO2uYolTKP4Z1xmoR6f0v6npgz2DbKnUmtHbYCSDUupK/8vfvcefqDzlQ0YwITE0//gnfpVNSAZiWoXV+1Ojmszq2IrIaWAakikgJ8CNgmYjMBwzW7GJf8dX+lQKotgu6OUKgqb1nFtOtBXXkpMQQFX58F89jn19El8eDiI7/V6ObzxKAMebTAyx+1Ff7U2ogVU1WAmhu72J9r7r+W47VsXxG+oCfCQ8NIXx4G8dK+YX+latRrarZGt7Z2ObivUM13uUutxmw+0epYKIJQI1q3S2AxjYXm47VMm9czyifKenax6+CmyYANWq5PcZb0vlQRTOFtU6unjvGOwJIE4AKdpoA1KhkjOGS37xDY5t147e10xoNtGRyCpl2fZ9JaTqdowpumgDUqFTT0klBrZOYcAdXzbFGH4eHhjA9M44xCVGMTYwiOlwnc1fBTf8FqFHpcJVV6fPPN5/N7tJGXtldzoTkaMIcIXxt2WSa27v8HKFS/qcJQI1KR6qs2j9T0+O8M3yNTYwCYNn0gYd/KhVstAtIjUqHq1qIjQglIz6CNrv/f2xSlJ+jUiqwaAJQo1J+VQuT02MREe+E7h87K9PPUSkVWLQLSI06Ho9hX3kTH5tlnfAvnJbG1nsuJS1O5/ZVqjdtAahR4+VdZXz2r5vIr26hweni7Jye6Sb05K/U8TQBqFHjlV3lvJ9fy5MfFACwKEdn81LqRDQBqFFjV4k1Sd1Tm4pIiQknJyXazxEpFdj0HoAa8Ywx7CxppLShzbvs4/PHaDlnpU5CE4Aa8f787lEeeP0AANfMG0OX28PdV8z0c1RKBT5NAGpEK6l38us3DzIjM464yFAeuGGOlnhQaoj0X4oakX7+6n6cnW7mjkvA7TH88sa5zB2X6O+wlBpRNAGogLW7pJGJaTHERvT9MzXG8Jf1RwG86yamamVPpT4qHQWkAlJHl5tr/riB25/MA6C1o4v3Dlfj8Riqmzu827V0dJEaG0FcZJi/QlVqxNIWgApItS2dAGw8UgvAXS/s5qWdZZw/JYVvXTINgJyUaApqnUzSq3+lTonPWgAi8piIVInInl7LkkVkjYgctn8nneg7VPCqaem5yt9eVM9LO8uICA3h/fxaVtkPel09dwyg3T9KnSpfdgE9Aazot+wu4G1jzFTgbfu9UsfpkwAK6wFY/18XkxkfySu7ygkRuNKe6CVHE4BSp8RnCcAYsx6o67f4WmCV/XoVcJ2v9q9Gthq7Cwjgw+IG4iJCSY+L4CsXTQLAY2BmVhy/+MQcPpk7zl9hKjWiDfdN4AxjTLn9ugLIGGxDEbldRPJEJK+6unp4olN+88GRWi761TpueWwL0LcFsP5gNdmp0YgInzs3G4BZWfGICJ9aPIGUWC30ptSp8NtNYGOMERFzgvUrgZUAubm5g26nRod3DlZRWOuksNZJu8tNTXNPC6C5o4vsZKubJ8wRws7/uRy0yoNSp224WwCVIpIFYP+uGub9qwBV3tjufV1S76S2tYPxyVHeaRyzexV2S4gOIyFKh30qdbqGOwG8CNxqv74V+M8w718FqIrGdiJCrT/HghonNS0dpMZGsGBCIgDxesJX6ozz5TDQ1cAHwHQRKRGR24BfAJeJyGHgUvu9GuXcHsM7B6tYf2jweznlTW2cOykFgFd3W3X9U2Mj+NqyyYjA8hk6kbtSZ5rP7gEYYz49yKpLfLVPFZj+/WEp331uJwAH719BRKgDsGbwOmdiCqmx4VQ2dnDlnCw2HqnhhQ9LARiXFMVZYxI49vOr/Ba7UqOZPgmsfK53nf7Kxg4mpESzt6yRO575kHnjEjhU2UKn20NWfCQut3W//8fXnsUNC3V4p1K+pAlA+Vxda8+InvLGNiakRPNcXgkAO+1ZvAAyE6L4v5dN42BlM7csyRnuMJUKOpoAlM/V9kkA7TQ6XbywvYSlU1IB2JBfA1gTt6+YnemXGJUKRpoAlM/VtXYwIzOOAxXNlDW28ad38mnu6OKeq2YyMyuejUdq+MnL+5meGefvUJUKKpoAlM/VtnQyLima8sZ2iuucvLyrnGvmjmFmVjwA501O5bVvXeDnKJUKPjofgPK5utZOUmLCyUqI5D87ymhu7+LquVn+DkupoKcJQPmUMYZ6ZyfJseGMSYzC2ekmIjSEpVNT/R2aUkFPE4Dyib++d5RdJQ00tXfhchtSYsI5b3IKcZGh3Hxutk7crlQA0H+F6oxr63Rz/yv7AXjpjqUApMSGc/2CcXzpgkn+DE0p1Yu2ANRpM8bQ1un2vi+qc3pfX/PHDQAkx2jJZqUCjSYAddqe2lzEzP95ncomq6LnsZpWAL62bDIAjhBhYorO2qVUoNEuIHXaXt5ZZv3eVU5aXASPrD8KwFcvmsy3L52Ky22IjdA/NaUCjf6rVKdN7MlZnt9WQmVTO7WtncRGhHpr9uu5X6nApF1AasjaXW5aO7oA2FncgLPTep1fZXX57Ctv8pZ9aLG3U0oFLk0Aasi+/vR2zr5/Dfe+uJdr//Q+f1ybT6PTRU1LB9+9bBrpcRGE25O6XDpT6/crFei0ca6GpN3lZu0BawbPJzYWALC9qJ786mYAzhobz28+OY/yhnZWzMkk3KHXFkoFOk0Aakg2Ha0FIDU2gstmZWCM4dXd5Ty7pZgwhzB7TALp8ZF+jlIp9VFoAlAntLeske/+YydVzR3EhDvY8N8XExnmYPWWIp7dWsxz20q4/cJJevJXagTSBKAGVNnUzqdXbmK6XcZ52fQ07lw+lcgwazrHOWMTvNveuXyKv8JUSp0GTQBqQM9uKeZoTSvHaltJig7jiS8s7rN+VlY891w5kyvnZhEXGeanKJVSp8MvCUBECoBmwA10GWNy/RGHGpjbY/j71iIAjIEJAzzFGxIifPlCreuj1EjmzxbAxcaYGj/uP2i5PYY/rD3M9QvGkt3r5O7xGB7dcIyDlc2UNbYTHe7A2ekmOznaj9EqpXxFx+oFoXcOVvHbtw7zwOsHvMuMMdzz7z389NX9/HObNWH7DQvHAZCdoglAqdHIXy0AA7wpIgb4izFmZf8NROR24HaACRMmDHN4o9uzW4sBaHd5yK9q4bltxUxKjWH1liK+cH4OHxY1cN38MYTZD3VN0BaAUqOSvxLAUmNMqYikA2tE5IAxZn3vDeyksBIgNzfX+CPI0cjZ2cU6+4GuXSUNXPrguwAkRIUxPSOOH141i5AQq7jPgYomwh0hzBuf6K9wlVI+5JcuIGNMqf27CvgXsPjEn1Bnyo6iBro8hoUTEqlp6fQub2xzccHUVO/JH2BGZjx7f/wxpmXE+SNUpZSPDXsLQERigBBjTLP9+nLgx8Mdx2jW1O7C4zH84rUDzBufyL6yJm5bOpHH3z/Gqg8KEYGbFo1ne1EDCVFhjEmMYn95E+dMSjnuu8K0pINSo5Y/uoAygH+JVUM4FHjGGPO6H+IYlTq7PMy9901iwh20drq9/f0v7yqj3ukCrKGdy2dkMCH5CL+8cS5v7avkUGUzi3OS/Rm6UmqYDXsCMMYcBeYN936Dxb7yJgBaO90kRodx5/KpTEiO5stP5gEQE+7gv1bMIC0ugvX/dTEAM7PiuXJuFgnR+kCXUsFEnwQe4TYcruHhd/O57+NnMSU9jg+L6r3rblmSw21LJ+LxGMYlRVHZ1M7mey49bnauhKgwFk5IGu7QlVJ+pglghPv1mwfZUdzAlb/fwPcun8besiYy4yO59+NnsXRqKmA9tfv9K2dSUNuqUzMqpbz0bDCC7ShuYEdxA184P4f8qhZ+9cZBEqLCWZSTxIrZmX22vXJOlp+iVEoFKh3iEaCMGfjRh+7lRbVObv7rZtLjIrhz+VS+f+VMXG5DTUsHn8wdP5yhKqVGKG0BBKCyhjbO+8Va/vy5hayYbV25G2MobWjjC49vJTslhtTYcJwuN6988wKSY8JJjgknNzuJ8NAQlk1P8/N/gVJqJNAEEIDeO1wNwH8/v5uPnZWJiHDn6g95eVc50eEOCmpbcbkNF05LY0KvOj1PfekcRMAeYquUUiekCSAA7ShuAKync3Pvf4tpGXF8cLSWq+dm8fVlU6h3dvKtZ3fwpaUT+3yue7IWpZQaCk0AflLd3MEL20u49bwc74l73YEqUmMjyCuo54KpqayYncn6Q9Ws2VdJWlwED9wwlxh7FM/Wey7RK32l1GnRBOAH7S43d67ezqajdYSHhmCMVZjttT0VpMdHUFzXxrXzx/DZc7L57DnZNLe76HIb78kftJtHKXX6NAEMswZnJ9f+6X0Ka52kxUXw+7cP09DmonvQT3FdG6EhwifsWvyATrmolPIJTQA+1u5yU9PSwdjEKO57aR9PbCxABJ784mLiIkO5+4XdzB6bQEeXBwzsr2jiqjlZjEmM8nfoSqlRThOAjxysaObFnaVsOlrHtsJ65oxNYHdpIwCfPWcCF06zhmq+/u0LAehyewCobe0kIUqv+JVSvqcJ4Ay5+4XdlNQ7uXVJDhvya3h2axHtLg8i8OnF43lzbyXnT0nhoU/OJzkm/LjPh9pllzPiI4c7dKVUkNIEcBqMMfzyjYP87YNCWjq6AHjvcA2OEOHaeWP45iVT6fIYpqTHcv91Vie/I0Rv3iqlAoMmgI+o3eXm0Q3HqGvtpKCmlbft6RUBttxzCf/aXsq5k1KOm0ZRT/xKqUCjCeAj6Ozy8NNX9vO3TYXEhDuICnfwvcunsXRqGi63h/S4SL5y0WR/h6mUUkOiCQBodLp493A1c8cmEBsZSlJ0OC/vKuOJjQV4DDgEPpk7ngfXHKKquYPPn5fDvR8/y99hK6XUaQnaBOBye8ivamFqeiw3rfyAAxXNjEmIpLqlg9iIUBraXIxLiiI+Moy9Fc1sL2pg3rgEfv6JOVw8Pd3f4Sul1GkLigRwoKKJyFAHOakxlDa0ce+Lewl3hPDK7nLvNpfPyuDNfZWMTYxiUU4Sk9Ji+fIFk4gKd7D+UDX1zk6umTuGEO3LV0qNEqM+AewobuDTKzcRGRbCj645i6c3F7K1oGfaxLPGxJMaG8Ffbj6bpzYXsTgnmemZcX2+o3vMvlJKjSZ+SQAisgL4HeAA/mqM+YUv9vOHtw/zu7cPkxEfSbvLzbf/vgOA+eMTKWto45kvn8OU9J6T/c3nZvsiDKWUCkjDngBExAH8CbgMKAG2isiLxph9Z3pf45OjuWnReL5z2TQiwxwU1TrJr27h0pnpRIY6tDtHKRXU/NECWAzkG2OOAojIs8C1wBlPANctGMt1C8Z6388aE8+sMfFnejdKKTUi+WNO4LFAca/3JfayPkTkdhHJE5G86urqYQtOKaWCRcBOCm+MWWmMyTXG5Kal6U1YpZQ60/yRAEqB8b3ej7OXKaWUGkb+SABbgakiMlFEwoFPAS/6IQ6llApqw34T2BjTJSJ3AG9gDQN9zBizd7jjUEqpYOeX5wCMMa8Cr/pj30oppSwBexNYKaWUb2kCUEqpICXGGH/HcFIiUg0UnsJHU4GaMxyOr2nMvjfS4oWRF/NIixdGZ8zZxphBx9GPiARwqkQkzxiT6+84PgqN2fdGWrww8mIeafFCcMasXUBKKRWkNAEopVSQGu0JYKW/AzgFGrPvjbR4YeTFPNLihSCMeVTfA1BKKTW40d4CUEopNQhNAEopFaRGbQIQkRUiclBE8kXkLn/HMxARKRCR3SKyQ0Ty7GXJIrJGRA7bv5P8HONjIlIlInt6LRswRrH83j7mu0RkYQDFfK+IlNrHeoeIXNlr3d12zAdF5GN+iHe8iKwTkX0isldEvmUvD9jjfIKYA/I4i0ikiGwRkZ12vPfZyyeKyGY7rr/bBSoRkQj7fb69Pmc44z1JzE+IyLFex3i+vfyj/10YY0bdD1aRuSPAJCAc2AnM8ndcA8RZAKT2W/ZL4C779V3AA36O8UJgIbDnZDECVwKvAQKcC2wOoJjvBb43wLaz7L+PCGCi/XfjGOZ4s4CF9us44JAdV8Ae5xPEHJDH2T5WsfbrMGCzfez+AXzKXv5n4Gv2668Df7Zffwr4ux+O8WAxPwHcOMD2H/nvYrS2ALzTThpjOoHuaSdHgmuBVfbrVcB1/gsFjDHrgbp+iweL8VrgSWPZBCSKSNawBNrLIDEP5lrgWWNMhzHmGJCP9fczbIwx5caY7fbrZmA/1ix5AXucTxDzYPx6nO1j1WK/DbN/DLAc+Ke9vP8x7j72/wQuEZFhnUT8BDEP5iP/XYzWBDCkaScDgAHeFJFtInK7vSzDGFNuv64AMvwT2gkNFmOgH/c77KbxY7261gIqZrurYQHW1d6IOM79YoYAPc4i4hCRHUAVsAarFdJgjOkaICZvvPb6RiBlOOOF42M2xnQf45/ax/ghEYnoH7PtpMd4tCaAkWKpMWYhcAXwDRG5sPdKY7XrAnqc7kiI0fYwMBmYD5QDv/FrNAMQkVjgeeDbxpim3usC9TgPEHPAHmdjjNsYMx9rFsLFwAz/RnRy/WMWkdnA3VixLwKSgf8+1e8frQlgREw7aYwptX9XAf/C+qOs7G622b+r/BfhoAaLMWCPuzGm0v7H5AEeoaf7ISBiFpEwrBPp08aYF+zFAX2cB4o50I8zgDGmAVgHLMHqJumeF6V3TN547fUJQO3wRtqjV8wr7O43Y4zpAB7nNI7xaE0AAT/tpIjEiEhc92vgcmAPVpy32pvdCvzHPxGe0GAxvgjcYo9GOBdo7NWF4Vf9+kKvxzrWYMX8KXvUx0RgKrBlmGMT4FFgvzHmwV6rAvY4DxZzoB5nEUkTkUT7dRRwGdZ9i3XAjfZm/Y9x97G/EVhrt8KGzSAxH+h1USBY9yx6H+OP9ncx3He2h+sH6474Iax+vnv8Hc8A8U3CGhWxE9jbHSNWP+PbwGHgLSDZz3GuxmrKu7D6FG8bLEas0Qd/so/5biA3gGL+mx3TLvsfSlav7e+xYz4IXOGHeJdide/sAnbYP1cG8nE+QcwBeZyBucCHdlx7gP+xl0/CSkT5wHNAhL080n6fb6+f5IdjPFjMa+1jvAd4ip6RQh/570JLQSilVJAarV1ASimlTkITgFJKBSlNAEopFaQ0ASilVJDSBKCUUkFKE4Aa1UTE3atq4g45SWVYEfmqiNxyBvZbICKpp/C5j4nIfWJVAn3tdONQ6kRCT76JUiNam7EepR8SY8yffRjLUFyA9XDSBcAGP8eiRjltAaigZF+h/1Ks+Ri2iMgUe/m9IvI9+/U3xap3v0tEnrWXJYvIv+1lm0Rkrr08RUTetOu2/xXroZzufX3O3scOEfmLiDgGiOcmu+jXN4HfYpVR+IKIBNQT7Gp00QSgRruofl1AN/Va12iMmQP8Eeuk299dwAJjzFzgq/ay+4AP7WXfB560l/8I2GCMOQurrtMEABGZCdwEnG+3RNzAZ/vvyBjzd6yKmnvsmHbb+/74qf+nK3Vi2gWkRrsTdQGt7vX7oQHW7wKeFpF/A/+2ly0FbgAwxqy1r/zjsSah+YS9/BURqbe3vwQ4G9hql5OPYvACf9OAo/brGGPV2VfKZzQBqGBmBnnd7SqsE/s1wD0iMucU9iHAKmPM3SfcyJoSNBUIFZF9QJbdJXSnMea9U9ivUielXUAqmN3U6/cHvVeISAgw3hizDqveegIQC7yH3YUjIsuAGmPVwV8PfMZefgXQPRHK28CNIpJur0sWkez+gRhjcoFXsGZ1+iVWccD5evJXvqQtADXaRdlX0t1eN8Z0DwVNEpFdQAfw6X6fcwBPiUgC1lX8740xDSJyL/CY/TknPSWD7wNWi8heYCNQBGCM2SciP8Ca+S0Eq0LpN4DCAWJdiHUT+OvAgwOsV+qM0mqgKiiJSAFWudwaf8eilL9oF5BSSgUpbQEopVSQ0haAUkoFKU0ASikVpDQBKKVUkNIEoJRSQUoTgFJKBan/DyxzWIHbPqoOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "# agent = Agent(state_size, action_size, random_seed=2)\n",
    "\n",
    "\n",
    "\n",
    "class Trainer():\n",
    "    \n",
    "    TARGET_SCORE = 30\n",
    "    def __init__(self, env, brain_name, agent, n_agents=1):\n",
    "        self.agent = agent\n",
    "        self.n_agents = n_agents\n",
    "        self.scores_deque = deque(maxlen=100)     # last 100 scores\n",
    "        self.scores_ep = []                       # list containing scores from each episode\n",
    "        self.env = env\n",
    "        self.brain_name = brain_name\n",
    "        self.max_score = 0                        # initialize agent max score \n",
    "\n",
    "        \n",
    "    def train(self, n_episodes=1000, max_t=500, print_every=100, verbose=True, save=True, \n",
    "              save_name='', stop=False):\n",
    "        \n",
    "        start_time = time.time()                   # register start time\n",
    "        num_agents = self.n_agents\n",
    "        \n",
    "        for i_episode in range(1, n_episodes+1):\n",
    "            env_info = self.env.reset(train_mode=True)[brain_name]   # Init Enviroment\n",
    "            states = env_info.vector_observations                    # Get Initial State\n",
    "            scores = np.zeros(self.n_agents)                            # array with episode scores\n",
    "\n",
    "            self.agent.reset()                                       # Reset Noise\n",
    "            for t in range(max_t):\n",
    "                actions = self.agent.act(states)\n",
    "\n",
    "                env_info = self.env.step(actions)[self.brain_name]\n",
    "    #             print(env_info.vector_observations.shape)\n",
    "                next_state = env_info.vector_observations\n",
    "                rewards = env_info.rewards\n",
    "                done = env_info.local_done\n",
    "                \n",
    "                for n in range(num_agents):\n",
    "                    self.agent.step(states[n], actions[n], rewards[n], next_state[n], done[n])\n",
    "                states = next_state\n",
    "                scores += rewards\n",
    "#                 print(done)\n",
    "                if np.any(done):\n",
    "                    break \n",
    "            self.scores_deque.append(np.mean(scores))\n",
    "            self.scores_ep.append(np.mean(scores))\n",
    "\n",
    "            exec_time = time.time() - start_time\n",
    "            print(f'\\rEpisode {i_episode}\\tAverage Score: {np.mean(self.scores_deque):.2f} ' + \\\n",
    "                  f'exec.time: {str(datetime.timedelta(seconds=exec_time))}', end=\"\")\n",
    "\n",
    "            if i_episode % print_every == 0 and verbose:\n",
    "                print(f'\\rEpisode {i_episode}\\tAverage Score: {np.mean(self.scores_deque):.2f} ' + \\\n",
    "                      f'exec.time: {str(datetime.timedelta(seconds=exec_time))}')\n",
    "\n",
    "            ## Check if eviroment is solved and save checkpoint\n",
    "            if np.mean(self.scores_deque) >= self.TARGET_SCORE and len(self.scores_deque) == 100:\n",
    "                if self.max_score == 0:\n",
    "                    print(' <-- Objective Achived!')\n",
    "                    print(f'- Average score of +{np.mean(self.scores_deque):.2f} over 100 consecutive episodes')\n",
    "\n",
    "                    if stop:\n",
    "                        print('- Trainining Finished -')\n",
    "                        print(f'- Total training time:\\t{str(datetime.timedelta(seconds=exec_time))}')\n",
    "                        \n",
    "                    \n",
    "                        if save:\n",
    "                            torch.save(self.agent.actor_local.state_dict(), f'checkpoint_actor_{save_name}.pth')\n",
    "                            torch.save(self.agent.critic_local.state_dict(), f'checkpoint__critic_{save_name}.pth')\n",
    "                            \n",
    "                            with open(f'scores_{save_name}.pkl', 'wb') as handle:\n",
    "                                pickle.dump(self.scores_ep, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                            \n",
    "                        return self.scores_ep, i_episode\n",
    "\n",
    "                if np.mean(self.scores_deque) >= self.max_score:\n",
    "                    max_score = np.mean(self.scores_deque)\n",
    "\n",
    "                    if save:\n",
    "                        torch.save(self.agent.actor_local.state_dict(), f'checkpoint_actor_{save_name}.pth')\n",
    "                        torch.save(self.agent.critic_local.state_dict(), f'checkpoint__critic_{save_name}.pth')\n",
    "\n",
    "        exec_time = time.time() - start_time                   # compute training time\n",
    "\n",
    "        ## save training scores\n",
    "        if save:\n",
    "            with open(f'scores_{save_name}.pkl', 'wb') as handle:\n",
    "                pickle.dump(self.scores_ep, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "        print('- Trainining Finished -')\n",
    "        print(f'\\t-Total training time:\\t{str(datetime.timedelta(seconds=exec_time))}')\n",
    "        if self.max_score > 0:\n",
    "            print(f'\\t-Maximum average score of +{max_score} over 100 consecutive episodes')\n",
    "        else:\n",
    "            if stop:\n",
    "                return self.scores_ep, 9999\n",
    "            print('!!! Objective NOT achived !!!')\n",
    "        return self.scores_ep\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def nn_gridsearch(hiper_dict,inter=1, n_episodes=30, max_t=700, save_name=''):\n",
    "    \"\"\"Grid Search for NN eural Network Hiperparameters.\n",
    "    \n",
    "    Find the best hiperparameter based on training speed (number of episodes taken to achive score of +13).\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        hiper_dict (dict): Hiperparameters dictionary with key = <hiperparameter attribute name> and value = \n",
    "                            <list of hiperparameter values to be searched>. ex:\n",
    "                            hiper_dict = {\n",
    "                                            'start_filter': [16, 32],\n",
    "                                            'layers': [1, 2],\n",
    "                                            'dropout': [0.1, 0.2]\n",
    "                                        } \n",
    "        inter (int): Number of intercations at each hiperparameter set.\n",
    "                        \n",
    "    \"\"\"\n",
    "    best_score = -1\n",
    "    best = {}\n",
    "    for hiper in itertools.product(*hiper_dict.values()):\n",
    "        h_dict = {k: h for k, h in zip(hiper_dict.keys(), hiper)}\n",
    "        \n",
    "        config = Config()\n",
    "        config.merge(h_dict)\n",
    "#         print(config)\n",
    "        print(h_dict)\n",
    "        for i in range(inter):\n",
    "            \n",
    "            agent = DDPG_Agent(state_size, action_size, random_seed=4200, config=config)\n",
    "            \n",
    "            trainer = Trainer(env, brain_name, agent, num_agents)\n",
    "            \n",
    "            scores, lst_episode = trainer.train(n_episodes=n_episodes, max_t=max_t, verbose=False, save=False, \n",
    "                          save_name=save_name, stop=True)\n",
    "\n",
    "            if np.mean(scores[-5:]) > best_score:\n",
    "                best_score = np.mean(scores[-min(n_episodes,100):])\n",
    "                best = h_dict\n",
    "\n",
    "            print('-'*20)\n",
    "    print(f'Best training score: {best_score}')\n",
    "    print('Best Hiperprameters:')\n",
    "    for k in best:\n",
    "        print(f'\\t{k}: {best[k]}')\n",
    "        \n",
    "    return best, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.99, 'tau': 0.001, 'lr_critic': 0.001, 'lr_actor': 0.0001, 'l2_reg': 0, 'clip_grad_act': 1, 'clip_grad_crit': 1, 'fc1_act': 400, 'fc2_act': 300, 'fc1_crit': 400, 'fc2_crit': 300, 'update_every': 5, 'update_times': 2, 'bn': True}\n",
      "Episode 50\tAverage Score: 21.29 exec.time: 1:44:31.978746- Trainining Finished -\n",
      "\t-Total training time:\t1:44:31.979709\n",
      "--------------------\n",
      "{'gamma': 0.99, 'tau': 0.001, 'lr_critic': 0.001, 'lr_actor': 0.0001, 'l2_reg': 0, 'clip_grad_act': 1, 'clip_grad_crit': 1, 'fc1_act': 400, 'fc2_act': 300, 'fc1_crit': 400, 'fc2_crit': 300, 'update_every': 5, 'update_times': 2, 'bn': False}\n",
      "Episode 50\tAverage Score: 3.13 exec.time: 1:24:57.094339- Trainining Finished -\n",
      "\t-Total training time:\t1:24:57.094339\n",
      "--------------------\n",
      "Best training score: 21.29408952404\n",
      "Best Hiperprameters:\n",
      "\tgamma: 0.99\n",
      "\ttau: 0.001\n",
      "\tlr_critic: 0.001\n",
      "\tlr_actor: 0.0001\n",
      "\tl2_reg: 0\n",
      "\tclip_grad_act: 1\n",
      "\tclip_grad_crit: 1\n",
      "\tfc1_act: 400\n",
      "\tfc2_act: 300\n",
      "\tfc1_crit: 400\n",
      "\tfc2_crit: 300\n",
      "\tupdate_every: 5\n",
      "\tupdate_times: 2\n",
      "\tbn: True\n"
     ]
    }
   ],
   "source": [
    "hiper_dict = {\n",
    "    'gamma': [.99],\n",
    "    'tau': [1e-3],\n",
    "    'lr_critic': [1e-3],\n",
    "    'lr_actor': [1e-4],\n",
    "    'l2_reg': [0],\n",
    "    'clip_grad_act': [1],\n",
    "    'clip_grad_crit': [1],\n",
    "    'fc1_act': [400],\n",
    "    'fc2_act': [300],\n",
    "    'fc1_crit': [400],\n",
    "    'fc2_crit': [300],\n",
    "    'update_every': [5],\n",
    "    'update_times': [2],\n",
    "    'bn': [True, False]\n",
    "}\n",
    "\n",
    "best, best_score = nn_gridsearch(hiper_dict, inter=1, n_episodes=50, max_t=1000, save_name='DDPG_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "\n",
    "config.buffer_size = int(1e6)\n",
    "config.batch_size = 128\n",
    "\n",
    "config.gamma = 0.99\n",
    "config.tau = 1e-3\n",
    "config.lr_critic = 5e-5\n",
    "config.lr_actor = 5e-5\n",
    "config.l2_reg = 0\n",
    "config.clip_grad_act = 1\n",
    "config.clip_grad_crit = 1\n",
    "\n",
    "config.fc1_act = 400\n",
    "config.fc2_act = 300\n",
    "config.fc1_crit = 400\n",
    "config.fc2_crit = 300\n",
    "config.update_every = 20\n",
    "config.update_times = 10\n",
    "config.bn = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DDPG_config.pkl', 'wb') as handle:\n",
    "    pickle.dump(config, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DDPG_Agent(state_size, action_size, random_seed=420, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(env, brain_name, agent, num_agents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 33.67 exec.time: 4:59:55.688323\n",
      " <-- Objective Achived!\n",
      "- Average score of +33.67 over 100 consecutive episodes\n",
      "- Trainining Finished -\n",
      "- Total training time:\t4:59:55.688323\n"
     ]
    }
   ],
   "source": [
    "scores, _ = trainer.train(n_episodes=500, max_t=1000, print_every=100, verbose=True, save=True, stop=True,\n",
    "                          save_name='DDPG_test_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn 0 Mean Score: 18.95299957636744\n"
     ]
    }
   ],
   "source": [
    "with open('DDPG_config.pkl', 'rb') as handle:\n",
    "    config = pickle.load(handle)\n",
    "\n",
    "agent = DDPG_Agent(state_size, action_size, random_seed=420, config=config)\n",
    "\n",
    "\n",
    "agent.actor_local.load_state_dict(torch.load('checkpoint_actor_DDPG_test_.pth'))\n",
    "agent.critic_local.load_state_dict(torch.load('checkpoint__critic_DDPG_test_.pth'))\n",
    "\n",
    "                                   \n",
    "for i in range(1):\n",
    "    env_info = env.reset(train_mode=False)[brain_name]   # Init Enviroment\n",
    "    states = env_info.vector_observations                    # Get Initial State\n",
    "    scores = np.zeros(num_agents)                            # array with episode scores\n",
    "\n",
    "    agent.reset()                                       # Reset Noise\n",
    "    for t in range(500):\n",
    "        actions = agent.act(states, add_noise=False)\n",
    "        env_info = env.step(actions)[brain_name]\n",
    "        next_state = env_info.vector_observations\n",
    "        rewards = env_info.rewards\n",
    "        done = env_info.local_done\n",
    "        states = next_state\n",
    "        scores += rewards\n",
    "#                 print(done)\n",
    "        if np.any(done):\n",
    "            break       \n",
    "    print(f'Turn {i} Mean Score: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn 0 Mean Score: 18.545999585464596\n"
     ]
    }
   ],
   "source": [
    "with open('PPO_config.pkl', 'rb') as handle:\n",
    "    config = pickle.load(handle)\n",
    "    \n",
    "config.brain_name = brain_name\n",
    "config.env = env\n",
    "\n",
    "agent = PPO_Agent(state_size, action_size, random_seed=420, config=config)\n",
    "\n",
    "\n",
    "agent.network.load_state_dict(torch.load('checkpoint_ppo_net_PPO_test_.pth'))\n",
    "\n",
    "                                   \n",
    "for i in range(1):\n",
    "    env_info = config.env.reset(train_mode=False)[brain_name]   # Init Enviroment\n",
    "    states = env_info.vector_observations                    # Get Initial State\n",
    "    scores = np.zeros(num_agents)                            # array with episode scores\n",
    "\n",
    "    agent.reset()                                       # Reset Noise\n",
    "    for t in range(500):\n",
    "        actions = agent.act(states, add_noise=False)\n",
    "        env_info = config.env.step(actions)[brain_name]\n",
    "        next_state = env_info.vector_observations\n",
    "        rewards = env_info.rewards\n",
    "        done = env_info.local_done\n",
    "        states = next_state\n",
    "        scores += rewards\n",
    "#                 print(done)\n",
    "        if np.any(done):\n",
    "            break       \n",
    "    print(f'Turn {i} Mean Score: {np.mean(scores)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
